// Generated from Perf.g4 by ANTLR 4.8
#![allow(dead_code)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(nonstandard_style)]
#![allow(unused_imports)]
#![allow(unused_mut)]
use antlr_rust::PredictionContextCache;
use antlr_rust::parser::{Parser, BaseParser, ParserRecog, ParserNodeType};
use antlr_rust::token_stream::TokenStream;
use antlr_rust::token_source::TokenSource;
use antlr_rust::parser_atn_simulator::ParserATNSimulator;
use antlr_rust::errors::*;
use antlr_rust::rule_context::{BaseRuleContext, CustomRuleContext, RuleContext};
use antlr_rust::recognizer::{Recognizer,Actions};
use antlr_rust::atn_deserializer::ATNDeserializer;
use antlr_rust::dfa::DFA;
use antlr_rust::atn::{ATN, INVALID_ALT};
use antlr_rust::error_strategy::{ErrorStrategy, DefaultErrorStrategy};
use antlr_rust::parser_rule_context::{BaseParserRuleContext, ParserRuleContext,cast,cast_mut};
use antlr_rust::tree::{TerminalNode, ErrorNode, ParseTree, ParseTreeWalker, LeafNode, ParseTreeListener, Listenable, Visitable};
use antlr_rust::token::{TOKEN_EOF,OwningToken,Token};
use antlr_rust::int_stream::EOF;
use antlr_rust::vocabulary::{Vocabulary,VocabularyImpl};
use antlr_rust::token_factory::{CommonTokenFactory,TokenFactory, TokenAware};
use super::perflistener::*;
use antlr_rust::lazy_static;

use std::marker::PhantomData;
use std::sync::Arc;
use std::rc::Rc;
use std::convert::TryFrom;
use std::cell::RefCell;
use std::ops::{DerefMut, Deref};
use std::borrow::{Borrow,BorrowMut};
use std::any::{Any,TypeId};

		pub const T__0:isize=1; 
		pub const T__1:isize=2; 
		pub const T__2:isize=3; 
		pub const T__3:isize=4; 
		pub const T__4:isize=5; 
		pub const T__5:isize=6; 
		pub const T__6:isize=7; 
		pub const T__7:isize=8; 
		pub const T__8:isize=9; 
		pub const T__9:isize=10; 
		pub const ID:isize=11; 
		pub const WS:isize=12;
	pub const RULE_stat:usize = 0; 
	pub const RULE_expr:usize = 1;
	pub const ruleNames: [&'static str; 2] =  [
		"stat", "expr"
	];


	pub const _LITERAL_NAMES: [Option<&'static str>;11] = [
		None, Some("';'"), Some("'.'"), Some("'not'"), Some("'and'"), Some("'or'"), 
		Some("'('"), Some("')'"), Some("'?'"), Some("':'"), Some("'between'")
	];
	pub const _SYMBOLIC_NAMES: [Option<&'static str>;13]  = [
		None, None, None, None, None, None, None, None, None, None, None, Some("ID"), 
		Some("WS")
	];
	lazy_static!{
	    static ref _shared_context_cache: Arc<PredictionContextCache> = Arc::new(PredictionContextCache::new());
		static ref VOCABULARY: Box<dyn Vocabulary> = Box::new(VocabularyImpl::new(_LITERAL_NAMES.iter(), _SYMBOLIC_NAMES.iter(), None));
	}


type BaseParserType<'input, I> =
	BaseParser<'input,PerfParserExt, I, PerfParserContextType , dyn PerfListener<'input> + 'static >;

type TokenType<'input> = <LocalTokenFactory<'input> as TokenFactory<'input>>::Tok;
pub type LocalTokenFactory<'input> = CommonTokenFactory;

pub type PerfTreeWalker<'input,'a> =
	ParseTreeWalker<'input, 'a, PerfParserContextType , dyn PerfListener<'input> + 'a>;

pub struct PerfParser<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> >> {
	base:BaseParserType<'input,I>,
	interpreter:Arc<ParserATNSimulator>,
	_shared_context_cache: Box<PredictionContextCache>,
    pub err_handler: Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> + 'input>,
}

impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> >> PerfParser<'input,I> {

	pub fn get_serialized_atn() -> &'static str { unimplemented!() }

    pub fn set_error_strategy(&mut self, strategy: Box<dyn ErrorStrategy<'input,BaseParserType<'input,I>> >) {
        self.err_handler = strategy
    }

    pub fn new(input: Box<I>) -> Self {
		antlr_rust::recognizer::check_version("0","2");
		let interpreter = Arc::new(ParserATNSimulator::new(
			_ATN.clone(),
			_decision_to_DFA.clone(),
			_shared_context_cache.clone(),
		));
		Self {
			base: BaseParser::new_base_parser(
				input,
				Arc::clone(&interpreter),
				PerfParserExt{
				}
			),
			interpreter,
            _shared_context_cache: Box::new(PredictionContextCache::new()),
            err_handler: Box::new(DefaultErrorStrategy::<'input,PerfParserContextType>::new()),
        }
    }
}

/// Trait for monomorphized trait object that corresponds to nodes of parse tree generated by PerfParser
pub trait PerfParserContext<'input>:
	for<'x> Listenable<dyn PerfListener<'input> + 'x > + 
	ParserRuleContext<'input, TF=LocalTokenFactory<'input>, Ctx=PerfParserContextType>
{}

impl<'input> PerfParserContext<'input> for TerminalNode<'input,PerfParserContextType> {}
impl<'input> PerfParserContext<'input> for ErrorNode<'input,PerfParserContextType> {}

pub struct PerfParserContextType;

impl<'input> ParserNodeType<'input> for PerfParserContextType{
	type TF = LocalTokenFactory<'input>;
	type Type = dyn PerfParserContext<'input> + 'input;
}

impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> > > Deref for PerfParser<'input,I> {
    type Target = BaseParserType<'input,I>;

    fn deref(&self) -> &Self::Target {
        &self.base
    }
}

impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> > > DerefMut for PerfParser<'input,I> {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.base
    }
}

pub struct PerfParserExt{
}

impl PerfParserExt{
}


impl<'input> TokenAware<'input> for PerfParserExt{
	type TF = LocalTokenFactory<'input>;
}

impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> > > ParserRecog<'input, BaseParserType<'input,I>> for PerfParserExt{}

impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> > > Actions<'input, BaseParserType<'input,I>> for PerfParserExt{
	fn get_grammar_file_name(&self) -> & str{ "Perf.g4"}

   	fn get_rule_names(&self) -> &[& str] {&ruleNames}

   	fn get_vocabulary(&self) -> &dyn Vocabulary { &**VOCABULARY }
	fn sempred(_localctx: &(dyn PerfParserContext<'input> + 'input), rule_index: isize, pred_index: isize,
			   recog:&mut BaseParserType<'input,I>
	)->bool{
		match rule_index {
					1 => PerfParser::<'input,I>::expr_sempred(cast::<_,ExprContext<'input> >(_localctx), pred_index, recog),
			_ => true
		}
	}
}
impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> > > PerfParser<'input,I>{
	fn expr_sempred(_localctx: &ExprContext<'input>, pred_index:isize,
						recog:&mut <Self as Deref>::Target
		) -> bool {
		match pred_index {
				0=>{
					recog.precpred(None, 5)
				}
				1=>{
					recog.precpred(None, 4)
				}
				2=>{
					recog.precpred(None, 2)
				}
			_ => true
		}
	}
}
//------------------- stat ----------------
pub type StatContextAll<'input> = StatContext<'input>;


pub type StatContext<'input> = BaseParserRuleContext<'input,StatContextExt<'input>>;

#[derive(Clone)]
pub struct StatContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> PerfParserContext<'input> for StatContext<'input>{}

impl<'input,'a> Listenable<dyn PerfListener<'input> + 'a> for StatContext<'input>{
	fn enter(&self,listener: &mut (dyn PerfListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_stat(self);
	}
}

impl<'input> CustomRuleContext<'input> for StatContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = PerfParserContextType;
	fn get_rule_index(&self) -> usize { RULE_stat }
	//fn type_rule_index() -> usize where Self: Sized { RULE_stat }
}
antlr_rust::type_id!{StatContextExt}

impl<'input> StatContextExt<'input>{
	fn new(parent: Option<Rc<dyn PerfParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<StatContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,StatContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait StatContextAttrs<'input>: PerfParserContext<'input> + BorrowMut<StatContextExt<'input>>{

fn expr(&self) -> Option<Rc<ExprContextAll<'input>>> where Self:Sized{
	self.child_of_type(0)
}

}

impl<'input> StatContextAttrs<'input> for StatContext<'input>{}

impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> > > PerfParser<'input,I>{
	pub fn stat(&mut self,)
	-> Result<Rc<StatContextAll<'input>>,ANTLRError> {
		let mut recog = self;
		let _parentctx = recog.ctx.take();
		let mut _localctx = StatContextExt::new(_parentctx.clone(), recog.base.get_state());
        recog.base.enter_rule(_localctx.clone(), 0, RULE_stat);
        let mut _localctx: Rc<StatContextAll> = _localctx;
		let result: Result<(), ANTLRError> = try {

			recog.base.set_state(10);
			recog.err_handler.sync(&mut recog.base)?;
			match  recog.interpreter.adaptive_predict(0,&mut recog.base)? {
				1 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 1);
					recog.base.enter_outer_alt(None, 1);
					{
					/*InvokeRule expr*/
					recog.base.set_state(4);
					recog.expr_rec(0)?;

					recog.base.set_state(5);
					recog.base.match_token(T__0,recog.err_handler.as_mut())?;

					}
				}
			,
				2 =>{
					//recog.base.enter_outer_alt(_localctx.clone(), 2);
					recog.base.enter_outer_alt(None, 2);
					{
					/*InvokeRule expr*/
					recog.base.set_state(7);
					recog.expr_rec(0)?;

					recog.base.set_state(8);
					recog.base.match_token(T__1,recog.err_handler.as_mut())?;

					}
				}

				_ => {}
			}
		};
		match result {
		Ok(_)=>{},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re) => {
				//_localctx.exception = re;
				recog.err_handler.report_error(&mut recog.base, re);
				recog.err_handler.recover(&mut recog.base, re)?;
			}
		}
		recog.base.exit_rule();

		Ok(_localctx)
	}
}
//------------------- expr ----------------
pub type ExprContextAll<'input> = ExprContext<'input>;


pub type ExprContext<'input> = BaseParserRuleContext<'input,ExprContextExt<'input>>;

#[derive(Clone)]
pub struct ExprContextExt<'input>{
ph:PhantomData<&'input str>
}

impl<'input> PerfParserContext<'input> for ExprContext<'input>{}

impl<'input,'a> Listenable<dyn PerfListener<'input> + 'a> for ExprContext<'input>{
	fn enter(&self,listener: &mut (dyn PerfListener<'input> + 'a)) {
		listener.enter_every_rule(self);
		listener.enter_expr(self);
	}
}

impl<'input> CustomRuleContext<'input> for ExprContextExt<'input>{
	type TF = LocalTokenFactory<'input>;
	type Ctx = PerfParserContextType;
	fn get_rule_index(&self) -> usize { RULE_expr }
	//fn type_rule_index() -> usize where Self: Sized { RULE_expr }
}
antlr_rust::type_id!{ExprContextExt}

impl<'input> ExprContextExt<'input>{
	fn new(parent: Option<Rc<dyn PerfParserContext<'input> + 'input > >, invoking_state: isize) -> Rc<ExprContextAll<'input>> {
		Rc::new(
			BaseParserRuleContext::new_parser_ctx(parent, invoking_state,ExprContextExt{
				ph:PhantomData
			}),
		)
	}
}

pub trait ExprContextAttrs<'input>: PerfParserContext<'input> + BorrowMut<ExprContextExt<'input>>{

/// Retrieves first TerminalNode corresponding to token ID
/// Returns `None` if there is no child corresponding to token ID
fn ID(&self) -> Option<Rc<TerminalNode<'input,PerfParserContextType>>> where Self:Sized{
	self.get_token(ID, 0)
}
fn expr_all(&self) ->  Vec<Rc<ExprContextAll<'input>>> where Self:Sized{
	self.children_of_type()
}
fn expr(&self, i: usize) -> Option<Rc<ExprContextAll<'input>>> where Self:Sized{
	self.child_of_type(i)
}

}

impl<'input> ExprContextAttrs<'input> for ExprContext<'input>{}

impl<'input,I: TokenStream<'input, TF=LocalTokenFactory<'input> > > PerfParser<'input,I> {

	pub fn  expr(&mut self,)
	-> Result<Rc<ExprContextAll<'input>>,ANTLRError> {
		self.expr_rec(0)
	}

	fn expr_rec(&mut self, _p: isize)
	-> Result<Rc<ExprContextAll<'input>>,ANTLRError> {
		let recog = self;
		let _parentctx = recog.ctx.take();
		let _parentState = recog.base.get_state();
		let mut _localctx = ExprContextExt::new(_parentctx.clone(), recog.base.get_state());
		recog.base.enter_recursion_rule(_localctx.clone(), 2, RULE_expr, _p);
	    let mut _localctx: Rc<ExprContextAll> = _localctx;
        let mut _prevctx = _localctx.clone();
		let _startState = 2;
		let result: Result<(), ANTLRError> = try {
			let mut _alt: isize;
			//recog.base.enter_outer_alt(_localctx.clone(), 1);
			recog.base.enter_outer_alt(None, 1);
			{
			recog.base.set_state(25);
			recog.err_handler.sync(&mut recog.base)?;
			match recog.base.input.la(1) {
			 ID 
				=> {
					{
					recog.base.set_state(13);
					recog.base.match_token(ID,recog.err_handler.as_mut())?;

					}
				}

			 T__2 
				=> {
					{
					recog.base.set_state(14);
					recog.base.match_token(T__2,recog.err_handler.as_mut())?;

					/*InvokeRule expr*/
					recog.base.set_state(15);
					recog.expr_rec(6)?;

					}
				}

			 T__5 
				=> {
					{
					recog.base.set_state(16);
					recog.base.match_token(T__5,recog.err_handler.as_mut())?;

					recog.base.set_state(17);
					recog.base.match_token(ID,recog.err_handler.as_mut())?;

					recog.base.set_state(18);
					recog.base.match_token(T__6,recog.err_handler.as_mut())?;

					/*InvokeRule expr*/
					recog.base.set_state(19);
					recog.expr_rec(3)?;

					}
				}

			 T__9 
				=> {
					{
					recog.base.set_state(20);
					recog.base.match_token(T__9,recog.err_handler.as_mut())?;

					/*InvokeRule expr*/
					recog.base.set_state(21);
					recog.expr_rec(0)?;

					recog.base.set_state(22);
					recog.base.match_token(T__3,recog.err_handler.as_mut())?;

					/*InvokeRule expr*/
					recog.base.set_state(23);
					recog.expr_rec(1)?;

					}
				}

				_ => Err(ANTLRError::NoAltError(NoViableAltError::new(&mut recog.base)))?
			}
			let tmp = recog.input.lt(-1).cloned();
			recog.ctx.as_ref().unwrap().set_stop(tmp);
			recog.base.set_state(41);
			recog.err_handler.sync(&mut recog.base)?;
			_alt = recog.interpreter.adaptive_predict(3,&mut recog.base)?;
			while { _alt!=2 && _alt!=INVALID_ALT } {
				if _alt==1 {
					recog.trigger_exit_rule_event();
					_prevctx = _localctx.clone();
					{
					recog.base.set_state(39);
					recog.err_handler.sync(&mut recog.base)?;
					match  recog.interpreter.adaptive_predict(2,&mut recog.base)? {
						1 =>{
							{
							/*recRuleAltStartAction*/
							let mut tmp = ExprContextExt::new(_parentctx.clone(), _parentState);
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_expr);
							_localctx = tmp;
							recog.base.set_state(27);
							if !({recog.precpred(None, 5)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 5)".to_owned()), None))?;
							}
							recog.base.set_state(28);
							recog.base.match_token(T__3,recog.err_handler.as_mut())?;

							/*InvokeRule expr*/
							recog.base.set_state(29);
							recog.expr_rec(6)?;

							}
						}
					,
						2 =>{
							{
							/*recRuleAltStartAction*/
							let mut tmp = ExprContextExt::new(_parentctx.clone(), _parentState);
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_expr);
							_localctx = tmp;
							recog.base.set_state(30);
							if !({recog.precpred(None, 4)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 4)".to_owned()), None))?;
							}
							recog.base.set_state(31);
							recog.base.match_token(T__4,recog.err_handler.as_mut())?;

							/*InvokeRule expr*/
							recog.base.set_state(32);
							recog.expr_rec(5)?;

							}
						}
					,
						3 =>{
							{
							/*recRuleAltStartAction*/
							let mut tmp = ExprContextExt::new(_parentctx.clone(), _parentState);
							recog.push_new_recursion_context(tmp.clone(), _startState, RULE_expr);
							_localctx = tmp;
							recog.base.set_state(33);
							if !({recog.precpred(None, 2)}) {
								Err(FailedPredicateError::new(&mut recog.base, Some("recog.precpred(None, 2)".to_owned()), None))?;
							}
							recog.base.set_state(34);
							recog.base.match_token(T__7,recog.err_handler.as_mut())?;

							/*InvokeRule expr*/
							recog.base.set_state(35);
							recog.expr_rec(0)?;

							recog.base.set_state(36);
							recog.base.match_token(T__8,recog.err_handler.as_mut())?;

							/*InvokeRule expr*/
							recog.base.set_state(37);
							recog.expr_rec(3)?;

							}
						}

						_ => {}
					}
					} 
				}
				recog.base.set_state(43);
				recog.err_handler.sync(&mut recog.base)?;
				_alt = recog.interpreter.adaptive_predict(3,&mut recog.base)?;
			}
			}
		};
		match result {
		Ok(_) => {},
        Err(e @ ANTLRError::FallThrough(_)) => return Err(e),
		Err(ref re)=>{
			//_localctx.exception = re;
			recog.err_handler.report_error(&mut recog.base, re);
	        recog.err_handler.recover(&mut recog.base, re)?;}
		}
		recog.base.unroll_recursion_context(_parentctx);

		Ok(_localctx)
	}
}

lazy_static! {
    static ref _ATN: Arc<ATN> =
        Arc::new(ATNDeserializer::new(None).deserialize(_serializedATN.chars()));
    static ref _decision_to_DFA: Arc<Vec<DFA>> = {
        let mut dfa = Vec::new();
        let size = _ATN.decision_to_state.len();
        for i in 0..size {
            dfa.push(DFA::new(
                _ATN.clone(),
                _ATN.get_decision_state(i),
                i as isize,
            ))
        }
        Arc::new(dfa)
    };
}



const _serializedATN:&'static str =
	"\x03\u{608b}\u{a72a}\u{8133}\u{b9ed}\u{417c}\u{3be7}\u{7786}\u{5964}\x03\
	\x0e\x2f\x04\x02\x09\x02\x04\x03\x09\x03\x03\x02\x03\x02\x03\x02\x03\x02\
	\x03\x02\x03\x02\x05\x02\x0d\x0a\x02\x03\x03\x03\x03\x03\x03\x03\x03\x03\
	\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x05\
	\x03\x1c\x0a\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\
	\x03\x03\x03\x03\x03\x03\x03\x03\x03\x03\x07\x03\x2a\x0a\x03\x0c\x03\x0e\
	\x03\x2d\x0b\x03\x03\x03\x02\x03\x04\x04\x02\x04\x02\x02\x02\x33\x02\x0c\
	\x03\x02\x02\x02\x04\x1b\x03\x02\x02\x02\x06\x07\x05\x04\x03\x02\x07\x08\
	\x07\x03\x02\x02\x08\x0d\x03\x02\x02\x02\x09\x0a\x05\x04\x03\x02\x0a\x0b\
	\x07\x04\x02\x02\x0b\x0d\x03\x02\x02\x02\x0c\x06\x03\x02\x02\x02\x0c\x09\
	\x03\x02\x02\x02\x0d\x03\x03\x02\x02\x02\x0e\x0f\x08\x03\x01\x02\x0f\x1c\
	\x07\x0d\x02\x02\x10\x11\x07\x05\x02\x02\x11\x1c\x05\x04\x03\x08\x12\x13\
	\x07\x08\x02\x02\x13\x14\x07\x0d\x02\x02\x14\x15\x07\x09\x02\x02\x15\x1c\
	\x05\x04\x03\x05\x16\x17\x07\x0c\x02\x02\x17\x18\x05\x04\x03\x02\x18\x19\
	\x07\x06\x02\x02\x19\x1a\x05\x04\x03\x03\x1a\x1c\x03\x02\x02\x02\x1b\x0e\
	\x03\x02\x02\x02\x1b\x10\x03\x02\x02\x02\x1b\x12\x03\x02\x02\x02\x1b\x16\
	\x03\x02\x02\x02\x1c\x2b\x03\x02\x02\x02\x1d\x1e\x0c\x07\x02\x02\x1e\x1f\
	\x07\x06\x02\x02\x1f\x2a\x05\x04\x03\x08\x20\x21\x0c\x06\x02\x02\x21\x22\
	\x07\x07\x02\x02\x22\x2a\x05\x04\x03\x07\x23\x24\x0c\x04\x02\x02\x24\x25\
	\x07\x0a\x02\x02\x25\x26\x05\x04\x03\x02\x26\x27\x07\x0b\x02\x02\x27\x28\
	\x05\x04\x03\x05\x28\x2a\x03\x02\x02\x02\x29\x1d\x03\x02\x02\x02\x29\x20\
	\x03\x02\x02\x02\x29\x23\x03\x02\x02\x02\x2a\x2d\x03\x02\x02\x02\x2b\x29\
	\x03\x02\x02\x02\x2b\x2c\x03\x02\x02\x02\x2c\x05\x03\x02\x02\x02\x2d\x2b\
	\x03\x02\x02\x02\x06\x0c\x1b\x29\x2b";

